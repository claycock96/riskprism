# LLM Provider Configuration
# Choose your LLM provider: "anthropic" or "bedrock"
LLM_PROVIDER=anthropic

# Anthropic API (if using LLM_PROVIDER=anthropic)
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-api-key-here

# Anthropic Model ID (optional, defaults to claude-3-5-haiku-20241022)
# Available models (as of Jan 2025):
#   claude-3-opus-20240229      - Most capable, expensive (~$15/$75 per M tokens)
#   claude-3-5-haiku-20241022   - Fast & affordable (~$0.80/$4 per M tokens) - RECOMMENDED
#   claude-3-haiku-20240307     - Cheapest (~$0.25/$1.25 per M tokens)
ANTHROPIC_MODEL=claude-3-5-haiku-20241022

# AWS Bedrock (if using LLM_PROVIDER=bedrock)
# AWS credentials can be configured via:
# 1. AWS CLI: aws configure
# 2. Environment variables (uncomment below):
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key
# AWS_REGION=us-east-1

# Bedrock Model ID (optional, defaults to anthropic.claude-3-5-sonnet-20241022-v2:0)
# BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0

# Frontend Configuration
# API URL for frontend to connect to backend (only needed if running outside Docker)
# Default in Docker: http://backend:8000
# NEXT_PUBLIC_API_URL=http://localhost:8000
